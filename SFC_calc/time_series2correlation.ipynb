{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f3a0a2-1c48-43a0-a8c3-03bcf276571c",
   "metadata": {},
   "source": [
    "# compute functional connectomes from timeseries and save as csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd3624-0f88-4c96-94a7-1d0a48b7f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "import glob\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b2b14c-f988-40d7-bb20-bb27e7712691",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "wd = (wd[:-10]+'/')\n",
    "path = wd+'216/'\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd67d0-9d49-42c7-8700-10fb979210f2",
   "metadata": {},
   "source": [
    "1) schaefer atals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67261ec-8a48-47fa-a29c-44eafa8989b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read dictionary pkl file\n",
    "with open(path+'/data/ukb_data_to_process/func', 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "for key, value in data.items():\n",
    "    df = value\n",
    "    df.to_csv(f'{path}/HC/time_series/{key}-sch.csv', index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bfe157-0c5a-4c5a-bbf8-308bee58863b",
   "metadata": {},
   "source": [
    "2) tian atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf8dc5f-99c0-40e2-949c-060abf570f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dictionary pkl file\n",
    "with open(path+'/ukb_data_to_process/fbc', 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "for key, value in data.items():\n",
    "    df = value\n",
    "    df.to_csv(f'{path}/HC/time_series/{key}-tian.csv', index=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f4a314-cda6-4152-96cd-3285d40d0420",
   "metadata": {},
   "source": [
    "concat the time series from cortical and subcortical atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a6141-2180-4a02-89a2-29d4d91f5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List of CSV files in each directory\n",
    "list_sch = glob.glob(path+'/HC/time_series/*-sch.csv')\n",
    "list_msaI = glob.glob(path+'/HC/time_series/*-tian.csv')\n",
    "\n",
    "# Sort files to ensure proper ordering\n",
    "list_sch.sort()\n",
    "list_msaI.sort()\n",
    "\n",
    "# Iterate through the files and concatenate them\n",
    "for file1, file2 in zip(list_sch, list_msaI):\n",
    "    \n",
    "    # Read CSV files\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    \n",
    "    # Concatenate dataframes\n",
    "    concatenated_df = pd.concat([df1, df2], axis=0)\n",
    "    \n",
    "    # Write concatenated dataframe to a new CSV file\n",
    "    concatenated_df.to_csv(f'{path}/HC/time_series/{file1[-15:-8]}_whole_brain.csv', index=False) \n",
    "    \n",
    "    print(f'Concatenated file created for {file1} and {file2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4386176-130c-40d8-a3cf-0ee63ef91b3c",
   "metadata": {},
   "source": [
    "### check for missing valus\n",
    "replacing their values with group avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c508ac1b-46de-4d0f-a685-916067b9b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_file = glob.glob(path+'/HC/time_series/*_whole_brain.csv')\n",
    "my_data = pd.DataFrame()\n",
    "for i in list_file:\n",
    "    df = pd.read_csv(i, index_col=0)\n",
    "    missing_values = df.isna().sum().sum()\n",
    "    if missing_values != 0:\n",
    "        print(i[-23:-16])\n",
    "        index_with_missing_values = df[df.isna().any(axis=1)].index\n",
    "        print(\"Index labels with missing values:\", index_with_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f03d9-af1b-4345-80d4-aca8987f9c2c",
   "metadata": {},
   "source": [
    "### If missing:\n",
    "edit to eid of subject with missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4b613-721b-4ed1-8617-664ad6710e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "eid='1234567'  # Example eid with missing values\n",
    "df = pd.read_csv(path+'/HC/time_series/'+eid+'_whole_brain.csv', index_col=0)\n",
    "column_means = df.mean()\n",
    "# Replace missing values in rows with the calculated averages\n",
    "for col in df.columns:\n",
    "    mask = df[col].isnull()  # Mask for missing values in the column\n",
    "    df.loc[mask, col] = column_means[col]\n",
    "df.to_csv(path+'/HC/time_series/'+eid+'_whole_brain.csv', index=True)\n",
    "df = pd.read_csv(path+'/HC/time_series/'+eid+'_whole_brain.csv', index_col=0)\n",
    "df.loc['7Networks_LH_Cont_Cing_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b6b13-f8fe-4065-bda8-8ffbf81d6f84",
   "metadata": {},
   "source": [
    "### Compute corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfdcbcf-c674-4e9c-909e-a4cce27e60a9",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67ab0e3c-a416-46ae-8043-9d6e319e63d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_file = glob.glob(path+'/HC/time_series/*_whole_brain.csv')\n",
    "my_data = pd.DataFrame()\n",
    "for i in list_file:\n",
    "    df = pd.read_csv(i, index_col=0)\n",
    "    time_series=df.values\n",
    "    time_series=np.transpose(time_series)\n",
    "    labels = df.index.values.tolist()\n",
    "    correlation_measure = ConnectivityMeasure(\n",
    "        kind=\"correlation\",\n",
    "        standardize=True,\n",
    "    )\n",
    "    correlation_matrix = correlation_measure.fit_transform([time_series])[0]\n",
    "    corre =  pd.DataFrame(correlation_matrix)\n",
    "    leb =  pd.DataFrame(labels)\n",
    "    # Save DataFrame to CSV\n",
    "    corre.to_csv(f'{path}/HC/func/{i[-23:-16]}-cor.csv', index=False, header=False)\n",
    "###    my_data = pd.concat([my_data, corre])\n",
    "\n",
    "leb.to_csv(f'{path}/HC/leb/sch200-msai-leb.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc78fa3-38c7-450e-8e2d-b4fc5c3ae833",
   "metadata": {},
   "source": [
    "partial correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a5c7f55-0bf7-450d-8449-826b28ccb447",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_file = glob.glob(path+'/HC/time_series/*_whole_brain.csv')\n",
    "my_data = pd.DataFrame()\n",
    "for i in list_file:\n",
    "    df = pd.read_csv(i, index_col=0)\n",
    "    time_series=df.values\n",
    "    time_series=np.transpose(time_series)\n",
    "    labels = df.index.values.tolist()\n",
    "    correlation_measure = ConnectivityMeasure(\n",
    "        kind=\"partial correlation\",\n",
    "        standardize=True,\n",
    "    )\n",
    "    correlation_matrix = correlation_measure.fit_transform([time_series])[0]\n",
    "    corre =  pd.DataFrame(correlation_matrix)\n",
    "    leb =  pd.DataFrame(labels)\n",
    "    # Save DataFrame to CSV\n",
    "    corre.to_csv(f'{path}/HC/func/{i[-23:-16]}-pcor.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
